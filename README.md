# Hi, I'm Jarupula Prem Kumar 

### Senior Data Engineer | Data Platform Architect

I specialize in designing, deploying, and optimizing high-performance, multi-cloud data ecosystems built for massive scale and reliability. My focus is translating complex analytical needs (R\&D, Data Science, Product) into robust, cost-efficient, and fully automated data infrastructure.

### Key Focus & Quantified Impact

My work centers on improving performance and governance across the data lifecycle:

| Metric | Achievement | Architectural Focus |
| :---- | :---- | :---- |
| **70%** | Infrastructure Cost Reduction | Re-architected high-volume ingestion (EventHub → ADLS → Spark) |
| **3x** | Throughput Increase | Optimized batch and streaming ETL workflows |
| **\<5s** | Real-Time Latency | Engineered **MQTT/Kafka** low-latency microservices |
| **99.9%** | Production Uptime | Maintained fault-tolerant streaming via robust **Observability (Prometheus/Grafana)** |

###  Core Capabilities

* **Real-Time Data Pipelining:** Design and deployment of high-volume, low-latency streaming platforms (Kafka, Spark) to maintain **sub-5s latency** and **99.9% uptime**.  
* **Architectural Optimization:** Expertise in data platform governance, leading architectural refactoring to secure **70% infrastructure cost savings** and **3x data throughput**.  
* **DevOps & MLOps:** Hands-on experience with production deployments on **Kubernetes**, leveraging **Argo CD** for CI/CD and **KEDA** for dynamic autoscaling.  
* **Data Modeling & Governance:** Implementing advanced data ingestion strategies (**CDC, SCD Type-0**) and establishing a **centralized source of truth** for analytical reliability.  
* **Cross-Functional Leadership:** Spearheading initiatives to integrate enriched data into business dashboards, enabling **Data Science** initiatives, and actively mentoring junior engineers.

- Architected P360 telemetry platform processing 30B+ EV/ICE events/day with sub-500ms p99 latency and 99.9% uptime, built for 10× future scale.  
- Engineered dual real-time ingestion systems (Kafka→ClickHouse & EventHub→Medallion) delivering 3× throughput and 70% infra cost reduction.  
- Built schema-aware Kafka pipelines with dynamic schema sync, DLQ routing, idempotent execution, and exactly-once guarantees.  
- Delivered enterprise CDC framework (Python/Polars) ingesting 20+ SAP/master-data systems with SCD0/2 modeling and autonomous schema-drift recovery.  
- Developed distributed Airflow/K8s aggregations generating trip, charge, diagnostic, and battery-health models from second-level telemetry.  
- Created production ETL/ELT pipelines with strict data contracts, backfill orchestration, and cross-team consumption readiness for ML/BI/Analytics.  
- Owned DevOps for telemetry microservices on AKS using ArgoCD, Helm, and KEDA autoscaling (0–50 workers), cutting compute cost 10%.  
- Implemented IaC + CI/CD with blue-green deployments reducing deployment time 80% and ensuring zero-downtime releases.  
- Established SLO-driven observability (Prometheus/Grafana/Loki) achieving 99.95% SLA, 60% MTTR reduction, and 90% incident reduction.  
- Optimized 20+ TB ClickHouse cluster with MergeTree tuning, partitioning, and materialized views improving p99 query latency by 60% (sub-2s).  
- Tuned Spark pipelines (AQE, skew mitigation, caching) improving batch processing throughput 50%.  
- Led 20+ TB archival migration to ADLS with Unity Catalog RBAC, lineage, governance, and retention, reducing storage cost 40%.  
- Built feature store + feature extraction frameworks in PySpark/Polars reducing ML data prep effort 80%.  
- Mentored 5 engineers and established engineering standards, halving pipeline time-to-production (6 weeks → 3 weeks).  


### Core Technology Stack

I primarily work across the cloud-native, modern data stack:

| Category | Skills & Technologies |
| :---- | :---- |
| **Big Data & Streaming** | Kafka, EventHub, Spark (PySpark), Polars, MQTT |
| **Data Warehousing** | ClickHouse, Snowflake, Delta Lake, PostgreSQL, MySQL |
| **Orchestration & ETL** | Apache Airflow, dbt, CDC, SCD Type-0 |
| **DevOps & MLOps** | Kubernetes, Docker, Argo CD, KEDA, CI/CD |
| **Languages** | Python (Advanced), SQL (Expert), Core Java |

### Let's Connect

I'm interested in collaborative projects involving real-time pipeline design, cost optimization, and platform reliability. Feel free to connect or check out my work below\!

**Find Me:**</br>
  - <b> Linkedin :</b> https://www.linkedin.com/in/jarupula-premkumar/
  - <b> Email :</b> jarupulapremkumar@gmail.com
